{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4CcC7yuWbJw"
   },
   "source": [
    "# Predict TripAdvisor Rating\n",
    "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fI0A6S6hWbJy"
   },
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "GVevQoNjWbJz"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sQK18_wiWbJ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "НЕ обнаружена среда выполнения Google Colab. Выбран режим локальной работы.\n"
     ]
    }
   ],
   "source": [
    "# проверка на работу в \"google colab\" или \"локально\"\n",
    "\n",
    "if 'sample_data' in os.listdir():\n",
    "    project_dir = r'/content/drive/My Drive/Colab Notebooks/module_3/'\n",
    "    print('Обнаружена среда выполнения Google Colab.')\n",
    "    print('project_dir =>', project_dir)\n",
    "else:\n",
    "    project_dir = ''\n",
    "    print('НЕ обнаружена среда выполнения Google Colab. Выбран режим локальной работы.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LcfyLlFpWbJ_"
   },
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc6oZ7I6NaoD"
   },
   "source": [
    "### Функции обработки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PVd96LNCWbKI"
   },
   "outputs": [],
   "source": [
    "def reviews_word_analyzer(incoming, mode='pos'):\n",
    "    ''' Оценка позитивной\\негативной окраски текстового сообщения.\n",
    "        Проверяется каждое слово на вхождение в список позитивных или негативных словарей.\n",
    "        Возвращается количество найденных вхождений.\n",
    "    '''\n",
    "    word_count = 0\n",
    "    # определяем справочник для проверки вхождения слов   \n",
    "    if type(incoming) is list:\n",
    "        incoming = ','.join(incoming)\n",
    "    if mode == 'pos':\n",
    "        control_list = pos_words\n",
    "    else:\n",
    "        control_list = neg_words\n",
    "    # подсчитываем количество вхождений    \n",
    "    for word in re.findall(r'[a-zA-Z\\-]+', incoming):\n",
    "        if word in control_list:\n",
    "            word_count += 1\n",
    "    return word_count\n",
    "# end function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrgJYzUikD1g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jNb40DwKVp-H",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def column_content_analysis(column_name_list, column_type='str', more_than = 10):\n",
    "    '''\n",
    "        Функция для определения типовых параметров данных, а также определние \"замусоренности\".\n",
    "        На вход принимает список столбцов датафрейма\n",
    "    '''\n",
    " # проходим циклом по списку колонок    \n",
    "    for column_name in column_name_list:\n",
    "        print('-'*60)\n",
    "        print('|\\t' , 'Отчет по колонке [', column_name, ']', '\\t'*5)\n",
    "        print('-'*60)\n",
    "        row_count = data.shape[0]\n",
    "        if column_name not in data.columns:\n",
    "            print('|  Внимание!!! Указанная колонка не найдена в датасете. \\n')\n",
    "            break\n",
    "\n",
    "        col_count = data[column_name].count()\n",
    "        col_type = data[column_name].dtype\n",
    "        print('|  Тип данных:', col_type) \n",
    "        print('|  Заполнено значений:',  col_count, 'из', row_count)\n",
    "        print('|  Отсутсвующие значения:', row_count - col_count)\n",
    "        print('|  Полнота данных: ', round(col_count / row_count * 100 ,2), '%', sep='')\n",
    "        print('|  Количество уникальных значений:', data[column_name].nunique())\n",
    "\n",
    "        print('|  Значений, встретившихся в столбце более', more_than,'раз:', \n",
    "              (data[column_name].value_counts() > more_than).sum())\n",
    "\n",
    "        if col_type == 'object':\n",
    "            # Количество пробелов в начале в конце строки\n",
    "            print('|  Количество раз пробелы найдены:')\n",
    "            find_list = [len(re.findall(r'^\\s+\\w?', str(x))) for x in data[column_name]]\n",
    "            print('|    в начале строки:', sum(find_list))\n",
    "            \n",
    "            find_list = [len(re.findall(r'\\w?\\s+$', str(x))) for x in data[column_name]]\n",
    "            print('|    в конце  строки:', sum(find_list))\n",
    "            \n",
    "            find_list = [len(re.findall(r'[^\\s\\d\\w]', str(x))) for x in data[column_name]]\n",
    "            print('|  Количество найденных специальных символов:', sum(find_list))\n",
    "        \n",
    "        if col_type in ['int', 'float']:\n",
    "            print('|  Медиана: ', data[column_name].median())\n",
    "            \n",
    "            perc25 = data[column_name].describe().loc['25%']\n",
    "            perc75 = data[column_name].describe().loc['75%']\n",
    "            iqr = perc75 - perc25\n",
    "            range_left = perc25 - 1.5 * iqr\n",
    "            range_right = perc75 + 1.5 * iqr\n",
    "            \n",
    "            # Границы выбросов\n",
    "            print('|  IQR: ', iqr, '; границы выбросов: [', round(range_left, 2), '; ', round(range_right,2),']' , sep='')\n",
    "            out_of_range_left = data[column_name].loc[data[column_name] < range_left]\n",
    "            out_of_range_right = data[column_name].loc[data[column_name] > range_right]\n",
    "            out_of_range = len(out_of_range_left) + len(out_of_range_right)\n",
    "            if out_of_range > 0:\n",
    "                print('|  Данные СОДЕРЖАТ выбросы, количество значений: ', out_of_range)\n",
    "                if len(out_of_range_left) > 0:\n",
    "                    print('|    Слева  от IQR (уникальные):', out_of_range_left.unique())\n",
    "                if len(out_of_range_right) > 0:\n",
    "                    print('|    Справа от IQR (уникальные):', out_of_range_right.unique())\n",
    "         \n",
    "        print('|---\\n|  Все уникальные значения:', data[column_name].unique() , '\\n')\n",
    "\n",
    "\n",
    "    # end function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viVZBCkxWbKL"
   },
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dc-42parXDYE"
   },
   "outputs": [],
   "source": [
    "# Выведем листинг проектного каталога\n",
    "for dirname, _, filenames in os.walk(project_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "Q7xEPPSEWbKM"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File main_task.csv does not exist: 'main_task.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c4e4fcf88b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'main_task.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'kaggle_task.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File main_task.csv does not exist: 'main_task.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_csv(project_dir + 'main_task.csv')\n",
    "df_test = pd.read_csv(project_dir + 'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(project_dir + 'sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HaBbN6RjWbKP"
   },
   "outputs": [],
   "source": [
    "# подключаем дополнительные источники - словари\n",
    "\n",
    "negotive = pd.read_csv(project_dir + 'neg_words.txt', names=['neg_word'], encoding='latin-1')\n",
    "positive = pd.read_csv(project_dir + 'positive-words.txt', names=['pos_word'], encoding='latin-1', comment=';')\n",
    "\n",
    "negotive.shape, positive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wibafZzHWbKU"
   },
   "outputs": [],
   "source": [
    "# словарь негативно окрашенных слов\n",
    "negotive.sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ne1PprtkWbKZ"
   },
   "outputs": [],
   "source": [
    "# подготовим список негативных слов\n",
    "neg_words = negotive['neg_word'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4SB48FXWbKb"
   },
   "outputs": [],
   "source": [
    "# словарь позитивно окрашенных слов\n",
    "positive.sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1GqvrFPWbKd"
   },
   "outputs": [],
   "source": [
    "# подготовим список слов с позитивной окраской\n",
    "pos_words = positive['pos_word'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWrPqtZ7WbKg"
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBzi_r6bWbKj"
   },
   "outputs": [],
   "source": [
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vfis-1c6WbKl"
   },
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mporFxfWbKo"
   },
   "outputs": [],
   "source": [
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Kcth03zWbKr"
   },
   "outputs": [],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAfCBwEZWbKt"
   },
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVBhyzCxWbKv"
   },
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oIM3M_xWbKy"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYFC0a92WbK0"
   },
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8cDlapDWbK0"
   },
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFV9zKnxnRUr"
   },
   "source": [
    "## Информация о колонках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xg20hbpgM9LQ"
   },
   "outputs": [],
   "source": [
    "# выведем детальный отчет по анализу данных в колонках\n",
    "\n",
    "column_content_analysis(data.columns, more_than=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgV_87gmWbK6"
   },
   "source": [
    "Как видим, большинство признаков у нас требует очистки и предварительной обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XomxtpeWWbK6"
   },
   "source": [
    "## Cleaning and Prepping Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BfjcX5BWbK7"
   },
   "source": [
    "## 1. Обработка NAN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFgeErsTWbK7"
   },
   "outputs": [],
   "source": [
    "# возмем столбец Number of Reviews\n",
    "data['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4RSjZPbWbK9"
   },
   "outputs": [],
   "source": [
    "data['Number_of_Reviews_isNAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_n9JvWVPWbK_"
   },
   "outputs": [],
   "source": [
    "# Далее заполняем пропуски 0, вы можете попробовать заполнением средним или средним по городу и тд...\n",
    "data['Number of Reviews'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGsvtcM0WbLC"
   },
   "source": [
    "# 2. Обработка признаков\n",
    "Посмотрим какие признаки у нас могут быть категориальными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmDUeLiRWbLC"
   },
   "outputs": [],
   "source": [
    "data.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At0loQ8UWbLF"
   },
   "source": [
    "Указанные признаки можно считать категориальными\n",
    "* City\n",
    "* Cuisine Style\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOVRWNu8WbK4"
   },
   "outputs": [],
   "source": [
    "# посмотрим на один из отзывов\n",
    "data.Reviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc4VJ8Iyom4k"
   },
   "source": [
    "Потребуется парсинг и разборе признака. Текстовые отзывы можно обработать на факт эмоционального окраса отзыва. После обрабокти сформировать дополнительные признаки.\n",
    "\n",
    "Даты отзывов можно трансформировать в признак, посчитав длительность между ними, например в минутах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZOmZRYKpLIE"
   },
   "source": [
    "## Кодирование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eeru_bD-WbLG"
   },
   "source": [
    "Для кодирования категориальных признаков есть множество подходов:\n",
    "* Label Encoding\n",
    "* One-Hot Encoding\n",
    "* Target Encoding\n",
    "* Hashing\n",
    "\n",
    "Выбор кодирования зависит от признака и выбраной модели.\n",
    "Не будем сейчас сильно погружаться в эту тематику, давайте посмотрим лучше пример с One-Hot Encoding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DMecHaaWbLG"
   },
   "outputs": [],
   "source": [
    "# для One-Hot Encoding в pandas есть готовая функция - get_dummies\n",
    "data = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QfpQyiKWbLN"
   },
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWGaBX5pWbLP"
   },
   "source": [
    "## \"Price Range\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5zgWAqNWbLP"
   },
   "outputs": [],
   "source": [
    "data['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYJbpUONWbLT"
   },
   "source": [
    "По описанию 'Price Range' это - Цены в ресторане.  \n",
    "Их можно поставить по возрастанию (значит это не категориальный признак). А это значит, что их можно заменить последовательными числами, например 1,2,3  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUqWQVPhWbLT"
   },
   "outputs": [],
   "source": [
    "# обработка 'Price Range'\n",
    "\n",
    "# подготовим словарь для конвертации значений\n",
    "price_range_dict = dict(zip(['$$ - $$$', '$', '$$$$'], [500, 5, 5000]))\n",
    "\n",
    "data['Price Range'] = data['Price Range'].replace(to_replace=price_range_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQn7kmanWbLV"
   },
   "outputs": [],
   "source": [
    "data['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZ_CqUeGWbLY"
   },
   "outputs": [],
   "source": [
    "data.columns[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bl327F_pwZK"
   },
   "source": [
    "## \"Cuisine Style\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGLkssoEWbLb"
   },
   "outputs": [],
   "source": [
    "data['Cuisine Style'] = data['Cuisine Style'].apply(lambda x: re.findall(r\"[^'][\\w\\s]+[^']\", str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKmOVQPiWbLd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.get_dummies(data.explode('Cuisine Style'), columns=['Cuisine Style'], prefix='CS', dummy_na=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqhQtYcuWbLh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_14IKLQWbLj"
   },
   "source": [
    "# EDA \n",
    "[Exploratory Data Analysis](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных) - Анализ данных\n",
    "На этом этапе мы строим графики, ищем закономерности, аномалии, выбросы или связи между признаками.\n",
    "В общем цель этого этапа понять, что эти данные могут нам дать и как признаки могут быть взаимосвязаны между собой.\n",
    "Понимание изначальных признаков позволит сгенерировать новые, более сильные и, тем самым, сделать нашу модель лучше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVt5InfYWbLj"
   },
   "source": [
    "### Посмотрим распределение признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gM8bBxmEWbLk"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,7)\n",
    "df_train['Ranking'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8TZT7imWbLm"
   },
   "source": [
    "У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NjcvC4EWbLn"
   },
   "outputs": [],
   "source": [
    "df_train['City'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Q1X-dojWbLr"
   },
   "source": [
    "А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afkvNXObWbLr"
   },
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzNftiRYWbLx"
   },
   "outputs": [],
   "source": [
    "# посмотрим на топ 10 городов\n",
    "for x in (df_train['City'].value_counts())[0:10].index:\n",
    "    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmkwtHOQWbL0"
   },
   "source": [
    "Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA9D9eAjWbL1"
   },
   "source": [
    "### Распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3X9UX4wWbL1"
   },
   "outputs": [],
   "source": [
    "df_train['Rating'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RNXyQn7WbL3"
   },
   "source": [
    "### Распределение целевой переменной относительно признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPiSlrAvWbL5"
   },
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xy9c0HvWbL8"
   },
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLXmKSrTWbL-"
   },
   "source": [
    "### Корреляция признаков\n",
    "На этом графике можно заметить, как признаки связаны между собой и с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDRN3muAWbL_"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "sns.heatmap(data.drop(['sample'], axis=1).corr(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPscu_EkWbMB"
   },
   "source": [
    "# Data Preprocessing\n",
    "Для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHg2pD4vWbMB"
   },
   "outputs": [],
   "source": [
    "# на всякий случай, заново подгружаем данные\n",
    "df_train = pd.read_csv(project_dir + 'main_task.csv')\n",
    "df_test = pd.read_csv(project_dir + 'kaggle_task.csv')\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUTJucC5WbML"
   },
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### 1. Предобработка ############################################################## \n",
    "    # убираем не нужные для модели признаки\n",
    "    df_output.drop(['Restaurant_id','ID_TA'], axis = 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # ################### 2. NAN ############################################################## \n",
    "    # Далее заполняем пропуски\n",
    "    df_output['Number of Reviews'].fillna(0, inplace=True)\n",
    "    # тут ваш код по обработке NAN\n",
    "    df_output['Price Range'].fillna('0', inplace=True)\n",
    "    \n",
    "    # для нулевых значений поставим средние значения по городу\n",
    "    number_of_reviews_mean = df_output.groupby('City')['Number of Reviews'].mean()\n",
    "    df_output['Number of Reviews'] = df_output.apply(lambda row: number_of_reviews_mean[row['City']] if row['Number of Reviews'] == 0 else row['Number of Reviews'], axis=1)\n",
    "    \n",
    "    \n",
    "    # ################### 3. Encoding ############################################################## \n",
    "    # get_dummies\n",
    "    \n",
    "    df_output = pd.get_dummies(df_output, columns=[ 'City',], dummy_na=True)\n",
    "    \n",
    "    price_range_dict = dict(zip(['$$ - $$$', '$', '$$$$', '0'], [500, 5, 5000, 0]))\n",
    "    df_output['Price Range'] = df_output['Price Range'].replace(to_replace=price_range_dict)\n",
    "\n",
    "    df_output['Cuisine Style'] = df_output['Cuisine Style'].apply(lambda x: re.findall(r\"[^'][\\w\\s]+[^']\", str(x)))\n",
    "\n",
    "    df_output = pd.concat([df_output, \n",
    "                 pd.get_dummies(df_output.explode('Cuisine Style')['Cuisine Style'], dummy_na=True)], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ################### 4. Feature Engineering ####################################################\n",
    "    #\n",
    "\n",
    "    df_output['score_pos'] = df_output['Reviews'].apply(lambda x: reviews_word_analyzer(str(x), mode='pos'))\n",
    "\n",
    "    df_output['score_neg'] = df_output['Reviews'].apply(lambda x: reviews_word_analyzer(str(x), mode='neg'))\n",
    "    \n",
    "    \n",
    "    df_output['reviews_data'] = df_output['Reviews'].apply(lambda x: re.findall(r\"\\d\\d\\/\\d\\d\\/\\d{4}\", str(x)) \n",
    "                                                           if len(re.findall(r\"\\d\\d\\/\\d\\d\\/\\d{4}\", str(x))) == 2\n",
    "                                                           else ['01/01/2000', '01/01/2000'])\n",
    "\n",
    "    df_output['reviews_delta'] = df_output['reviews_data'].apply(lambda x: (datetime.timestamp(datetime.strptime(x[0], '%m/%d/%Y')) \n",
    "                                                                    - datetime.timestamp(datetime.strptime(x[1], '%m/%d/%Y')))/60 )\n",
    "    \n",
    "    # ################### 5. Clean #################################################### \n",
    "    # убираем признаки которые еще не успели обработать, \n",
    "    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберем их и удалим\n",
    "    \n",
    "    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n",
    "    df_output.drop(object_columns, axis = 1, inplace=True)\n",
    "    \n",
    "    return df_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWfk3j4TqXrj"
   },
   "source": [
    "Новые признаки:\n",
    "\n",
    "1.  `score_pos` - числовая оценка положительного окраса отзыва\n",
    "2.  `score_neg` - числовая оценка отрицтельного окраса отзыва\n",
    "3. `reviews_delta` - количество минут между послденим и предпоследним отзывом\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGHL1Zk_WbMT"
   },
   "source": [
    "#### Запускаем и проверяем что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_aNOPF1WbMU"
   },
   "outputs": [],
   "source": [
    "df_preproc = preproc_data(data)\n",
    "df_preproc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yp7k_NKFWbMX"
   },
   "outputs": [],
   "source": [
    "df_preproc.sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrHbZcPrWbMk"
   },
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuAk7BclWbMq"
   },
   "source": [
    "Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxP82QDvWbMq"
   },
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UGroBeQsWbMt"
   },
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8b-GgXnWbMw"
   },
   "source": [
    "### Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQzz27s6WbMw"
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TGbf5hLWbMy"
   },
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbUh2PpGWbM1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSKv2sSgWbM4"
   },
   "outputs": [],
   "source": [
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qj4Is0onEaND"
   },
   "source": [
    "# MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lc-RnxghWbM7"
   },
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8iyjD48tEL4"
   },
   "source": [
    "*  Исходное значение метрики:\n",
    "> MAE: 0.21240125\n",
    "\n",
    "* Добавлен обработчик пустых значений для количества отзывов. Устанавливает среднее по городу.  Изменение метрики:\n",
    "> MAE: 0.0995425\n",
    "\n",
    "* Добавлена дельта времени между отзывами в минутах.  Изменение метрики:\n",
    "> MAE: 0.089500\n",
    "\n",
    "*  Небольшое изменение логики обработки пустых значений.  Изменение метрики:\n",
    "> MAE: 0.089434\n",
    "\n",
    "* Добавлена оценка отзывов на наличие негативных или позитивных слов. Изменение метрики:\n",
    "> MAE: 0.0875\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYbQcQUJWbM-"
   },
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH0QsOD3WbNA"
   },
   "source": [
    "### Submission\n",
    "Готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVBF03dwWbNA"
   },
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4w_-XDgbWbNC"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGEOVV2wWbND"
   },
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0_oyHCuWbNF"
   },
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oULaj4jLWbNG"
   },
   "outputs": [],
   "source": [
    "# приведем рейтинг к кратности шага 0.5\n",
    "predict_submission = list(map(lambda x: round(x * 2)/2, predict_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JpZ7UH9WbNK"
   },
   "outputs": [],
   "source": [
    "# посмотрим что получилось\n",
    "len(predict_submission), predict_submission[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXwJyjQRWbNM"
   },
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission[0:10000]\n",
    "sample_submission.to_csv(project_dir + 'submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AT5cEu97WbNO"
   },
   "source": [
    "# Выводы\n",
    "\n",
    "Чтобы улучшить результат:\n",
    "* Обработали и превратили оставшиеся признаки в понятный для машины формат - цифровые признаки.\n",
    "* Придумали, что еще можно извлечь из признаков и расширили набор исходных данных.\n",
    "* Сгенерировать новые признаки.\n",
    "* Подгрузить дополнительные данные - обработка содержрания отзывов на ключевые показатели.\n",
    "* Подобрали состав признаков.\n",
    "* Структурное изменение датафрейма с `11` до `167` столбцов.\n",
    "* Сократили `MAE`: c `0.2124` до `0.0875`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERrMWvTbs8tU"
   },
   "source": [
    "# Спасибо за внимание!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83Mjg2sNvg8I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "r-gat-sf-tripadvisor-rating-v2-7.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
